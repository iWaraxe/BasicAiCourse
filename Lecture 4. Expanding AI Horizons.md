# Beginners AI. Mastering modern AI tools

## Lecture 4. Specialized AI tools and advanced workflows

### 1. Introduction

#### 1.1. Course Context and Objectives

##### [seq:010] Introduction: Recap and What's Next

###### SCRIPT

Welcome back, everyone, to our final lecture in the Basic AI Course‚Äîand congratulations for making it this far!

Over the last three sessions, we‚Äôve taken quite a journey together.

In Lecture 1, we met the AI giants‚ÄîChatGPT, Claude, Perplexity, Gemini, and Mistral‚Äîand we also met their flaws. From biases to hallucinations, we learned to question AI rather than blindly trust it.

In Lecture 2, we flipped the lens‚Äîexploring real-life tasks where AI shines. We wrote essays, debugged code, translated idioms, and even analyzed visuals. We learned how to use the tools.

Then in Lecture 3, we peeked under the hood: exploring advanced UI features, reasoning chains, system prompts, and even multi-agent models.

Today is where it all comes together.
We‚Äôre going beyond the UI‚Äîinto the backstage of AI systems:
- You‚Äôll learn how to use LLM APIs to build and automate
- You‚Äôll explore benchmarking and prompt precision techniques
- You‚Äôll meet specialized AI tools like NotebookLM, Gamma, and HeyGen
- And we‚Äôll discuss how to keep up with AI's rapid evolution

This lecture is your launchpad‚Äîso that you not only understand today‚Äôs tools but can adapt to tomorrow‚Äôs.

Let‚Äôs get started.

###### VISUAL

**Slide Title: "Lecture 4: Expanding AI Horizons"**

- Left side: ‚ÄúWhere We‚Äôve Been‚Äù
	- Lecture 1: *AI Assistants & Limitations*
	- Lecture 2: *Text, Code, Visuals in Practice*
	- Lecture 3: *Advanced UI, Reasoning & Personalization*
- Right side: ‚ÄúWhere We‚Äôre Going Today‚Äù
	- APIs & Prompt Precision
	- Benchmarking & LLM Arena
	- Specialized Tools (NotebookLM, Gamma, etc.)
	- Staying Updated

**Visuals**:
- Icons or simple illustrations for each domain: gears for API, trophy for benchmarking, puzzle pieces for integration, radar screen for staying current.

###### NOTES

- **Tone Tip**: You‚Äôre guiding the class toward independence‚Äîhighlight the *why* behind every tool and strategy today.
- **Fun Fact**: OpenAI‚Äôs Playground used to be text-only with no memory and limited formatting. Today, you can tweak temperature, set roleplay scenarios, and simulate product UIs in a browser.
- **Joke**: ‚ÄúIn Lecture 1, AI hallucinated. In Lecture 2, it coded. In Lecture 3, it reasoned. Today? It becomes your lab assistant, graphic designer, video editor, and research analyst. All before lunch.‚Äù
- **Mention**:
	- [https://platform.openai.com/playground](https://platform.openai.com/playground)
	- [https://console.anthropic.com](https://console.anthropic.com)
	- [https://www.llmarena.com](https://www.llmarena.com)
	- [https://notebooklm.google](https://notebooklm.google)

###### DEMONSTRATION

**Title:** "How Precise is ChatGPT Today?"
**Prompt:**
```TeXt
Write an essay on the Titanic that is *exactly* 300 words. Do not present the answer until you‚Äôve confirmed it meets the word count. If it‚Äôs not exact, revise and count again.

```
**Instructions**:
- Run in ChatGPT Pro or GPT-4o.
- If it overshoots, revise live to show the edit loop.
- Show how we can use `https://wordcounter.net/` to double-check results.

**Discussion Prompt**:
> "This might seem pedantic‚Äîbut in technical writing, compliance, and academia, word count precision *matters*. How do you think AI performs when we force it to follow rigid constraints?"

### 2. API Integration and Advanced Prompting

#### 2.1. API Fundamentals

##### [seq:020] Understanding APIs and LLM Integration

###### SCRIPT
"To really unlock the power of modern AI, we need to go beyond the chatbot interface and step into the world of APIs.

So what exactly is an API? An API, or Application Programming Interface, is like a universal translator between your code and someone else's service‚Äîin this case, a powerful AI model running on a remote server.

APIs enable integration of LLMs into custom workflows and applications. With the introduction of 1 million token context windows in GPT-4.1, API integrations can now support bulk document processing, complex data cross-referencing, and persistent memory across very large sessions. This opens up new possibilities for enterprise-scale automation and analysis.

With just a few lines of code or even a no-code tool, you can:
- Send a prompt to GPT-4, Claude 4, Gemini, or Mistral
- Customize its behavior with parameters
- Get back structured data, completions, or summaries in seconds
- Process entire books or year's worth of reports in a single request
- Build sophisticated AI agents with Mistral's new Agents API featuring code execution, web search, and persistent memory
- Create no-code agents using LangChain's Open Agent Platform (OAP)

This is what powers real-world applications‚Äîfrom customer service bots to automated legal summarizers to AI-powered dashboards and autonomous AI agents.

Let's look at the OpenAI Playground and Anthropic Console‚Äîthese are visual front-ends for the APIs that let us tinker with models without writing any code.

We'll explore key parameters like:
- Temperature: controls randomness
- Max Tokens: caps the response length
- Top-p: narrows the sampling universe
- System prompts: secretly guide how the model behaves

Whether you're building a startup or a hobby project, understanding these controls is your first step toward AI integration mastery."

###### VISUAL
**Slide Title: "LLM APIs: What They Are & Why They Matter"**

| Concept          | Explanation                                           | Real-World Use     |
| ---------------- | ----------------------------------------------------- | ------------------ |
| API              | Interface to access AI models programmatically        | Chatbots, apps     |
| Playground       | GUI tool to test prompts with OpenAI models           | Fast prototyping   |
| Console (Claude) | Similar testing ground for Anthropic models           | Prompt fine-tuning |
| Temperature      | Controls creativity/randomness (0 = strict, 1 = wild) | Writing vs. fact   |
| Max Tokens       | Limits response size                                  | Trimming outputs   |
| System Prompt    | Behind-the-scenes instruction                         | Role assignment    |

**Visuals:**
- Diagrams of API request/response flow
- Flowchart showing an API sending large batches of data (e.g., multiple reports or datasets) to GPT-4.1 for unified response
- Screenshots of OpenAI Playground and Claude Console
- Emoji thermometer next to "temperature" setting for humor

###### NOTES
- Link to OpenAI API documentation on large-context usage, limits, and best practices
- **Tip**: Use metaphors ‚Äî "The API is the waiter; your prompt is the order; the model is the chef."
- **Trivia**: The first version of GPT-3 API launched in 2020 and had no memory, no chat history‚Äîjust one-shot text completion.
- **Joke**: "Setting temperature to 1 is like giving your AI a Red Bull and telling it to be creative. Setting it to 0? You've got Spock."
- **Cost Alert (June 2025)**: O3 Pro API costs $111 per task, Gemini 2.5 Pro ~$42/task, Claude 4 Opus $7.31 for complex tasks. Consider cost controls and model selection based on task requirements.
- **Benchmark Update**: Gemini 2.5 Pro leads in value (86% coding accuracy at ~$42/task vs O3's $111), while local models like Qwen3 235B show promise for open-weight deployment
- Mention:
  - [OpenAI Playground](https://platform.openai.com/playground)
  - [Anthropic Console](https://console.anthropic.com)
  - [Google Vertex AI](https://cloud.google.com/vertex-ai)
- **Optional Visual Aid**: Draw or animate the "prompt in ‚Üí response out" pipeline with labeled boxes.

###### DEMONSTRATION
- Example API use case: Show an API workflow where an HR system sends an entire year's worth of employee feedback for trend analysis in a single request using GPT-4.1's expanded context window.
- Alternative: Demonstrate local deployment with open models (Qwen, Mistral) for cost-sensitive or privacy-critical applications
---

##### [seq:030] Demo 1: Demonstration of Prompt Parameters

###### DEMONSTRATION

**Demo 1: Prompt Parameters in Action**

**Tool:** OpenAI Playground
**Prompt:**
```TeXt
Explain the difference between a black hole and a wormhole in simple terms.
```
**Instructions:**
- Run it with **temperature = 0** and **max tokens = 100**
- Then again with **temperature = 0.9** and **max tokens = 300**
- Compare responses side by side

**Talking Point:**  
> ‚ÄúNotice how the creative one adds metaphors and storytelling, while the low-temp one sticks to facts. This is useful when you're deciding whether you want **creativity or control**.‚Äù

---

##### [seq:040] Demo 2: System Prompt Power (Claude Console)

###### DEMONSTRATION

**System Prompt:**  
```TeXt
You are an overly dramatic science fiction writer.
```

**User Prompt:**
```TeXt
Describe the formation of a black hole.
```

**Instructions:**
- Run in Anthropic Console with Thinking Mode enabled
- Observe tone and ‚Äúpersona‚Äù shift based on system prompt

**Discussion Prompt:**  
> "If system prompts are like backstage instructions, how would you use this to shape a brand‚Äôs voice‚Äîor prevent hallucinations in high-risk use cases?"

---

#### 2.2. Precision Prompting Techniques

##### [seq:050] Advanced Prompt Crafting Techniques

###### SCRIPT

Welcome to the art and science of precision prompting.
Up until now, we‚Äôve been writing prompts like casual messages to an assistant. But with the right techniques, prompts can become precise instructions‚Äîlike code.
Why is this important?
Because the moment you rely on AI for structured outputs‚Äîwhether for reports, essays, code, or data‚Äîyou need control.
In this section, we‚Äôll focus on three areas:
1. Word count mastery ‚Äì how to make the model hit exact lengths, like 300 or 5000 words
2. Token awareness ‚Äì how to think like the model by understanding its building blocks
3. Prompt wizardry ‚Äì clever structures that force better reasoning or formatting

Let‚Äôs dive into some prompt magic that would make even Hogwarts jealous.

###### VISUAL

**Slide Title: "Precision Prompting: When Words Matter"**

| Technique           | Description                                         | Use Case                        |
| ------------------- | --------------------------------------------------- | ------------------------------- |
| Word Budgeting      | Telling the model to write exactly N words          | Essays, compliance, SEO         |
| Token Awareness     | Understanding how models break down text            | Avoiding truncation             |
| Segmented Prompting | Breaking large tasks into chunks for better control | Long reports, code blocks       |
| Prompt Wizardry     | Embedding hidden logic or rules into prompts        | Structured outputs, QA, scoring |

**Visuals:**
- Side-by-side screenshots of a 300-word essay vs a 512-word essay
- Diagram: ‚ÄúWords ‚Üí Tokens ‚Üí Output Budget‚Äù
- Magic wand icon for ‚Äúwizardry‚Äù effect

###### NOTES

- **Trivia**: A single token is about 4 characters. ‚ÄúBanana‚Äù = 1 token. ‚ÄúArtificial intelligence‚Äù = 3 tokens. GPT-4 Turbo handles up to 128,000 tokens.
- **Joke**: ‚ÄúPrecision prompting is like cooking with an AI sous-chef. If you don‚Äôt specify ‚Äòone clove of garlic,‚Äô you might get a vampire-safe pizza.‚Äù
- **Pro Tip**: Use tools like [OpenAI Tokenizer](https://platform.openai.com/tokenizer) and [https://wordcounter.net](https://wordcounter.net) to test outputs.
- **Suggested Prompt Library Reference**: `BaiL4Pr1` and `BaiL4Pr2` from your TextExpander snippets

---

#### 3.1. Demonstrations

##### [seq:060] Demo A ‚Äì 300-Word Precision Essay

###### DEMONSTRATION

**Prompt** (`BaiL4Pr1`):

```TeXt
Programmatically craft a precisely 300-word essay on the Titanic. Ensure it's exactly 300 words before presenting it. If it is not 300 exactly, make minor adjustments to the length by adding/removing the amount needed to hit the target. Before making these adjustments, estimate the exact number of words to add/remove. Use manual segmentation. Make small incremental changes as needed, but keep a tally of each word as you add or remove it in order to stay on budget.
```


**Instructions**:

- Run in ChatGPT with system prompt: ‚ÄúYou must follow all instructions exactly, no matter what.‚Äù
- Count result using [https://wordcounter.net](#)(https://wordcounter.net)
- If incorrect, show how to revise

**Discussion Prompt**:
> ‚ÄúHow does the model ‚Äòthink‚Äô about length? Where does it usually fail? Could we chain this with a tokenizer to get more accuracy?‚Äù

---

##### [seq:070] Demo B ‚Äì Token Counting Trick

###### DEMONSTRATION

**Prompt** (`BaiL4Pr3`):  
```TeXt
How many Rs are in "strawberry"?
How many Rs are in "coralberry"?
How many Rs are in "carry forward"?
```

**Instructions**:
- Run in Claude and ChatGPT
- Observe hallucinated vs correct outputs
- Bonus: Have students solve it manually to compare

**Discussion Prompt**:
> ‚ÄúWhy do some models hallucinate simple counts? What does this say about token vs character vs phoneme reasoning?‚Äù

---

##### [seq:080] Demo C ‚Äì 5000-Word Research Essay Builder

###### DEMONSTRATION

**Prompt** (`BaiL4Pr2`):
```TeXt
Programmatically craft a 5000 (+/-1%) word essay on [Insert Topic].
...
Use segmentation. Because this essay is quite long, consider breaking it into ten sections...
```

**Instructions**:
- Start it live, explain how section word budgets work
- You don‚Äôt have to run the whole essay, just show the **segmentation loop**
- Mention how this powers workflows for researchers, lawyers, or content creators

**Discussion Prompt**:
> ‚ÄúIf we think of longform writing as budgeting, what other AI tasks might benefit from this approach?‚Äù

---

### 3. Model Benchmarking and Comparison

#### 3.1. Evaluation Frameworks

##### [seq:090] AI Arena & Benchmarking

###### SCRIPT

It's time to bring out the big guns.
So far, we've explored prompt design and integration‚Ä¶ but how do we actually compare models like GPT-4, Claude, Gemini, Mistral, and the groundbreaking DeepSeek-R1-0528?
Welcome to the LLM Arena‚Äîa framework for testing, evaluating, and battling language models across a wide range of prompts.
Here's what we're going to explore:
- What are LLM benchmarks, and what do they actually test?
- How can you set up mini-benchmarks for your own tasks?
- What can tools like LLM Arena show us that casual use can‚Äôt?
We‚Äôll go hands-on with prompt matchups‚Äîcomparing speed, accuracy, tone, and creativity.
Think of it as the World Cup for AI.

###### VISUAL

**Slide Title: "LLM Benchmarking: Who Wins Where?"**

| Model      | Known Strengths                            | Weak Spots              |
| ---------- | ------------------------------------------ | ----------------------- |
| GPT-4      | Reasoning, structure, multilingual support | Occasional overthinking |
| Claude     | Ethics, logic, long context                | Subtle formatting gaps  |
| Gemini     | Multimodal tasks, clean formatting         | Still maturing in logic |
| Mistral    | Lightweight, local inference               | Lacks broader context   |
| **DeepSeek-R1-0528** | **First open-source SOTA model, outperforms o3 on coding** | **Higher token usage for reasoning** |

**Visuals:**
- Logos of GPT-4, Claude 3, Gemini, Mistral in corners
- Diagram showing different evaluation axes: creativity, reasoning, accuracy, verbosity
- Screenshot of [https://llmarena.com](https://llmarena.com)

###### NOTES

- **Tip**: Use metaphors like sports leagues, where GPT-4 is a chess champion, Claude is the philosopher, Gemini is the multimedia artist, Mistral is the indie underdog, and DeepSeek-R1-0528 is the open-source champion who just beat the professionals.
- **Breaking**: DeepSeek-R1-0528 (May 28, 2025) - First open-source model to achieve state-of-the-art performance, marking shift in AI leadership
- **Joke**: ‚ÄúThe only thing missing here is live commentary and dramatic theme music‚Äîbut don‚Äôt tempt me.‚Äù
- Mention:
	- [https://llmarena.com](https://llmarena.com) for side-by-side model evaluations
	- Academic benchmark sets: MMLU, BigBench, ARC
	- Leaderboards (like LMSYS or HuggingFace) for up-to-date results

---

#### 3.2. Comparative Testing

##### [seq:100] Demo A ‚Äì Real-Time Arena Test (Creative Output)

###### DEMONSTRATION

**Prompt**:
```TeXt
Describe the first contact between humans and an alien species in under 100 words. Include emotion, tension, and a twist.
```

**Instructions**:
- Run the prompt in GPT-4, Claude, Gemini, and Mistral (separately or using [https://chat.lmsys.org](#)(https://chat.lmsys.org) if available).
- Show all results side-by-side on screen

**Discussion Prompt**:
> ‚ÄúWhich one made you *feel* something? Which was the most concise? Which one surprised you?‚Äù

---

##### [seq:110] Demo B ‚Äì Accuracy Challenge

###### DEMONSTRATION

**Prompt**:  
```TeXt
What are the three key provisions of the Universal Declaration of Human Rights?
```

**Instructions**:
- Run in all models
- Fact-check with [https://www.un.org/en/about-us/universal-declaration-of-human-rights](https://www.un.org/en/about-us/universal-declaration-of-human-rights)
- Look for hallucinations, vague responses, and citation attempts

**Discussion Prompt**:
> ‚ÄúWho got it right? Who played it safe? Who added fluff?‚Äù

---

##### [seq:120] Demo C ‚Äì Speed & Brevity Test

###### DEMONSTRATION

**Prompt**:
```TeXt
Explain blockchain to a 10-year-old in 2 sentences.
```

**Instructions**:
- Time each response (fun stopwatch moment)
- Note which model hit the tone and kept it short

**Discussion Prompt**:
> ‚ÄúIf you had to put this in a school newsletter, which one would you use?‚Äù

---

##### [seq:130] Bonus Mini-Challenge ‚Äì Creative Rewrite

###### DEMONSTRATION

**Prompt**:  
```TeXt
Rewrite the nursery rhyme 'Jack and Jill' as a crime noir opening paragraph.
```

**Instructions**:
- Run in Claude and GPT-4o for fun comparison
- Read both aloud dramatically üòé

**Discussion Prompt**:
> ‚ÄúWhich model has more style? Which felt more like a *genre* than a gimmick?‚Äù

---

### 4. AI-Enhanced Image Processing

#### 4.1. Programmatic Image Editing

##### [seq:140] Advanced AI-Enhanced Image Editing

###### SCRIPT

Let‚Äôs take a break from text and look at the visual side of AI.
While most people associate image generation with tools like Midjourney or DALL¬∑E, there's another powerful angle: image editing with AI using code.
One of the most versatile tools for this is the Pillow library‚Äîalso known as PIL. It‚Äôs like Photoshop‚Äôs nerdy cousin: no fancy UI, but total control.
What‚Äôs exciting is that we can prompt ChatGPT to write Pillow scripts that apply filters, transformations, and artistic styles‚Äîwithout needing to touch Photoshop.
In this section, we‚Äôll:
- Convert images to greyscale, pixelated, or sepia
- Add dramatic effects like vignettes and Ben-Day dots
- Try out some artistic transformations like oil painting or retro pixel art
You‚Äôll see how generative AI can collaborate with code to unlock creativity in a whole new way.

###### VISUAL

**Slide Title: "AI + Code = Visual Magic"**

| Technique    | Effect Example            | Use Case                 |
| ------------ | ------------------------- | ------------------------ |
| Greyscale    | Black-and-white with mood | Film look, stylization   |
| Vignette     | Darkened edges for drama  | Focus viewer attention   |
| Pixelation   | Retro aesthetic           | Game art, fun visuals    |
| Sepia        | Vintage tone              | Historical feel          |
| Band Merge   | Swap color channels       | Experimental art         |
| Oil Painting | Simulate brush strokes    | Artistic transformations |

**Visuals**:
- Grid of before-and-after images showing each effect
- Callout: ‚ÄúAll edits generated using ChatGPT + Pillow (no Photoshop!)‚Äù

###### NOTES

- **Fun Fact**: The Python Imaging Library (PIL) dates back to the 1990s. Pillow is its modern fork‚Äîand it works beautifully with AI-generated code.
- **Joke**: ‚ÄúIt‚Äôs like having a moody digital intern with Photoshop skills and a Python habit.‚Äù
- **Tip**: Let students know they can use free tools like [Google Colab](https://colab.research.google.com/) or [Replit](https://replit.com/) to run Python + Pillow code even without setup.
- Mention:
	- `pip install pillow` for local setup
	- Link to Pillow‚Äôs official docs: [https://pillow.readthedocs.io](https://pillow.readthedocs.io)

---

#### 5.4. Demonstrations

##### [seq:150] Demo A ‚Äì Classic Image Edits (Greyscale + Vignette)

###### DEMONSTRATION

**Prompt to ChatGPT**:
```TeXt
Write Python Pillow code to take an uploaded image, convert it to greyscale, and add a soft vignette effect around the edges.
```

**Instructions**:

- Upload a test image (e.g., whiteboard photo or headshot)
- Copy-paste generated code into a Jupyter notebook or Replit
- Show original and edited versions side-by-side

**Discussion Prompt**:
> ‚ÄúWhat would it take to recreate this manually in Photoshop? How long did this take with AI + code?‚Äù

---

##### [seq:160] Demo B ‚Äì Ben-Day Dots / Comic Book Style

###### DEMONSTRATION

**Prompt** (`BaiL4Pr5`):  

```TeXt
Revise the image Ben-Day style, in big solid color dots. Retain the colors against a background of black.
```

**Instructions**:

- Run the code in Python
- Zoom into the result to show the dot pattern

**Bonus**: Print out a before/after and ask ‚ÄúWhich one would you post on Instagram?‚Äù

---

##### [seq:170] Demo C ‚Äì Oil Painting & Pixel Art Mashup

###### DEMONSTRATION

**Prompt**:  

```TeXt
Apply an oil painting effect to the image using Pillow. Then pixelate the image to look like vintage Nintendo games.
```

**Instructions**:

- Explain that true oil-paint filters require plug-ins or deeper code (simulate with filters + smoothing)
- Show how AI can chain two effects in one script

**Discussion Prompt**:
> ‚ÄúImagine chaining this with DALL¬∑E image variation or Upscale tools. How far could we push generative design workflows?‚Äù

---

##### [seq:180] Demo D ‚Äì Remix and Band Merge

###### DEMONSTRATION

**Prompt**:  
```TeXt
Split the RGB bands of the image and merge them in a new order (e.g., BGR). Add a color overlay to accent one band.
```

**Instructions**:

- This is more experimental‚Äîshow how you can create funky tints and neon-glitch effects
- Use a vibrant image with multiple colors

**Discussion Prompt**:
> ‚ÄúThis feels like algorithmic art. Could we train AI to *learn* our favorite styles and automate full design cycles?‚Äù

---

### 5. Specialized AI Applications

#### 5.1. Domain-Specific Tools

##### [seq:190] Specialized AI Tools

###### SCRIPT

So far, we‚Äôve worked mostly with general-purpose LLMs. But now, let‚Äôs explore the specialized side of AI‚Äîtools that take the power of large models and apply them to specific tasks.

These tools aren‚Äôt just chatbots. They‚Äôre interactive research assistants, visual designers, presentation builders, and content curators.

Think of them like‚Ä¶ domain-specific superpowers:
- Need to analyze a 30-page report? ‚Üí Use NotebookLM
- Want to turn text into a clean slideshow? ‚Üí Try Gamma
- Have a brainstorm to organize visually? ‚Üí Call Napkin.ai
- Need to summarize a news article in Spanish? ‚Üí Meet ReadPartner
- Want to make a realistic AI avatar video? ‚Üí Say hi to HeyGen
- Need ethical AI guidance before deploying? ‚Üí Try IBM's Responsible Prompting API
- Want high-quality, detailed image generation? ‚Üí Use Chroma v34

You don‚Äôt need to know code to use any of them.
Let‚Äôs walk through each one and see how they can amplify your thinking.

###### VISUAL

**Slide Title: "Specialized AI Tools: Your Creative Sidekicks"**

| Tool        | Superpower                                 | Use Case                       |
| ----------- | ------------------------------------------ | ------------------------------ |
| NotebookLM  | Reads, summarizes, and reasons with docs   | Reports, whitepapers, guides   |
| Gamma       | Turns text into presentations              | Pitch decks, explainer slides  |
| Napkin.ai   | Organizes your ideas visually              | Brainstorms, note clustering   |
| ReadPartner | Summarizes articles/videos (multi-lingual) | Learning, content research     |
| HeyGen      | Creates talking-head AI videos             | Explainers, marketing, avatars |
| IBM PromptAPI | Pre-inference responsible prompting guidance | Ethical AI, safety, accuracy  |
| Chroma v34  | High-resolution image generation            | Art creation, detailed visuals |

**Visuals:**
- Logos/screenshots of each tool in action
- Clean 2x3 layout with ‚Äúuse case‚Äù badges underneath

###### NOTES

- **Tip**: Emphasize these are *low-barrier tools*. Most use drag & drop, uploads, or text boxes‚Äî*no code required*.
- **Joke**: ‚ÄúIf ChatGPT is your generalist AI, these are like the weirdly talented friends who only do one thing‚Äî*but do it brilliantly*.‚Äù
- Mention:
	- [https://notebooklm.google](https://notebooklm.google)
	- [https://gamma.app](https://gamma.app)
	- [https://napkin.one](https://napkin.one)
	- [https://readpartner.com](https://readpartner.com)
	- [https://heygen.com](https://heygen.com)
	- IBM Responsible Prompting API (HF Spaces demo available)
	- Chroma v34 (available in detail-calibrated version)

---

##### [seq:195] Agent Platforms ‚Äì **Mistral Agents API & LangChain OAP**

###### SCRIPT

"Before we dive into specialized tools, let's talk about the newest evolution in AI: agent platforms.

In May 2025, two major developments changed the landscape of AI automation:

**Mistral's Agents API** brings enterprise-grade agent capabilities to developers. It features:
- Code execution in Python sandboxes for safe computation
- Web search integration using Brave
- Document library with hosted RAG
- Persistent memory across conversations
- Model Context Protocol (MCP) support
- Multi-agent orchestration with handoff capabilities

**LangChain's Open Agent Platform (OAP)** democratizes agent creation with a no-code approach. You can:
- Set up tools and supervisor agents through a web UI
- Connect to MCP servers for extended functionality
- Manage custom agents without writing code
- Deploy intelligent agents for real-world tasks

These platforms represent the 'LLM OS' concept coming to life‚Äîwhere AI agents don't just respond to prompts but actively execute tasks, maintain state, and collaborate with other agents."

###### VISUAL

**Slide Title: "The Rise of AI Agent Platforms"**

| Platform | Key Features | Best For |
|----------|-------------|----------|
| Mistral Agents API | Code execution, web search, persistent memory | Developers building production agents |
| LangChain OAP | No-code interface, MCP support, visual workflows | Business users & rapid prototyping |

**Diagram**: Flow showing agent ‚Üí tools ‚Üí actions ‚Üí results

###### NOTES

- These platforms are part of the emerging "LLM OS" stack
- MCP (Model Context Protocol) is becoming a standard for tool integration
- Both platforms support multi-agent workflows
- Links: mistral.ai/agents, langchain.com/open-agent-platform

###### DEMONSTRATION

**Quick Demo**: Show how to create a simple agent that:
1. Searches for information
2. Processes it with code
3. Maintains memory of the task

---

##### [seq:200] Demo A ‚Äì **NotebookLM** (Q&A Over Documents)

###### DEMONSTRATION

**Demo Setup**:

- Upload a scientific paper or a PDF whitepaper
- Ask:
	```plaintext
	‚ÄúWhat are the three key findings in this report?‚Äù
	‚ÄúExplain the methodology used in Section 2.‚Äù
	‚ÄúGenerate a study guide for this document.‚Äù
	```

**Instructions**:

- Show how NotebookLM responds in real-time with citations and summaries
- Navigate between document and answer window

**Discussion Prompt**:
> ‚ÄúHow might this replace old-school ‚ÄòCtrl+F and skim‚Äô workflows? What risks come from relying on AI for summaries?‚Äù

---

##### [seq:210] Demo B ‚Äì **Gamma** (AI Slide Deck Generator)

###### DEMONSTRATION

**Prompt**:
```plaintext
Create a presentation about the benefits of AI in education.
```

**Instructions**:

- Show how Gamma takes a paragraph and turns it into a clean, editable presentation
- Edit one slide live to demonstrate customization

**Bonus**: Paste your own text and watch Gamma turn it into slides *live*

**Discussion Prompt**:
> ‚ÄúCould this change how we build presentations in fast-paced work environments? When would you still need PowerPoint?‚Äù

---

##### [seq:220] Demo C ‚Äì **Napkin.ai** (Brainstorming Canvas)

###### DEMONSTRATION

**Demo Setup**:

- Create a simple idea cluster: "Launching a podcast"
- Input notes like:
	- ‚ÄúName ideas: MicDrop, EarFuel, The Morning Loop‚Äù
	- ‚ÄúNeed cover art, distribution, theme music‚Äù
	- ‚ÄúWeekly vs monthly schedule?‚Äù

**Instructions**:

- Show how Napkin visualizes and clusters notes dynamically
- Link related ideas and highlight emerging patterns

**Discussion Prompt**:
> ‚ÄúWhat kinds of work‚Äîcreative, strategic, personal‚Äîwould benefit from this kind of thinking canvas?‚Äù

---

##### [seq:230] Demo D ‚Äì **ReadPartner** (Live Summarization)

###### DEMONSTRATION

**Demo Options**:
- Summarize a YouTube video
- Translate a news article into Spanish and summarize

**Prompt Example**:  
```plaintext
Summarize this article in 200 words and translate it into Spanish.
```

**Instructions**:

- Use the browser extension or upload via link
- Highlight output‚Äôs clarity and multilingual capability

**Discussion Prompt**:
> ‚ÄúWhere would multilingual summarization help you in real life? Journalism? Learning? Travel?‚Äù

---

##### [seq:240] Demo E ‚Äì **HeyGen** (Talking AI Avatars)

###### DEMONSTRATION

**Demo Setup**:

- Use the free HeyGen version or pre-generated clip
- Upload script:
	```plaintext
	Welcome to our AI tools showcase. I'm your digital assistant, and today we'll explore five tools that turn your ideas into action.
	```

**Instructions**:

- Show avatar lip-syncing and tone delivery
- Point out avatar customization features

**Discussion Prompt**:
> ‚ÄúWhere could you *actually* use this? Internal company training? YouTube intros? Personalized customer service?‚Äù

---

#### 5.2. Integrated Workflows

##### [seq:250] Combining Tools for Extraordinary Results

###### SCRIPT

Okay, we‚Äôve explored some amazing individual tools‚Äîbut what happens when we combine them?

This is where real transformation begins. When you link research, analysis, visualization, and presentation tools together, you create something greater than the sum of its parts: a workflow powered by AI.

Think of it like an assembly line of brilliance:

Research with Perplexity

Visualize with Claude or NotebookLM

Present with Gamma

In this section, I‚Äôll walk you through a real-world example‚Äîbuilding a strategic industry report using multiple AI tools in a smooth pipeline.

This isn‚Äôt just faster‚Äîit‚Äôs smarter, more scalable, and adaptable for your job, business, or creative work.

Let‚Äôs see what that looks like in action.

###### VISUAL

**Slide Title: "Cross-Platform Workflows = Superhuman Output"**

**Workflow Visualization:**

```mermaid
graph LR
A[Perplexity: Deep Research] --> B[Claude: Summarize + Visualize]
B --> C[Gamma: Slide Deck Generator]
C --> D[HeyGen: Video Presentation]
```

**Callout Examples:**
- ‚Äú10,000-word industry report in 90 minutes‚Äù
- ‚ÄúInvestor pitch deck from a PDF + 3 prompts‚Äù
- ‚ÄúClient onboarding videos generated overnight‚Äù

**Visuals:**
- Icons/logos of each tool arranged in a pipeline
- Arrow flow showing data moving from one to the next

###### NOTES

- **Analogy**: This is like chaining LEGO bricks‚Äîeach tool has a *shape* that fits perfectly into the next if you know how to use it.
- **Joke**: ‚ÄúSuddenly your Sunday project turns into a boardroom-ready report‚Äîwith animations.‚Äù
- **Mention**:
	- Medium article inspiration: [The 4-Step Framework to Create Research Reports in Minutes with AI](https://medium.com/publishous/the-4-step-framework-to-create-powerful-research-reports-in-minutes-with-ai-516913559fc8)

---

##### [seq:260] Demo ‚Äì Electric Vehicle Outlook Report (2030)

###### DEMONSTRATION

**Step 1 ‚Äì Research in Perplexity**

**Prompt**:  

```mermaid
Find Electric vehicle industry outlook reports for 2030 globally. Focus on:
- Market trends
- Consumer spending
- Technologies
- Growth forecasts
Use site:deloitte.com OR site:mckinsey.com filetype:pdf
```

- Show link previews, export as citations
- Copy key insights

**Step 2 ‚Äì Visualization in Claude (or NotebookLM)**

**Claude Project Setup:**

- Paste research summary and prompt:
```mermaid
Create 3 charts:
- Global EV adoption trends (2015‚Äì2030)
- Charging infrastructure by country
- Consumer interest vs battery range
```

- Specify corporate palette: Deep Blue, Silver Grey
- Claude generates visuals + short executive summaries

**Step 3 ‚Äì Presentation in Gamma**

**Prompt**:
```mermaid
Create a 10-slide boardroom presentation titled ‚ÄúEV Market Trends Through 2030,‚Äù based on the following summary + charts.
```

- Paste content from Claude
- Gamma formats it with animations and clean layout

**Step 4 ‚Äì Optional: Narrated Video in HeyGen**

**Script**:  
```mermaid
This is the Electric Vehicle Industry Outlook Report. Over the next decade, we expect EV adoption to reach 40% globally...
```

- Show how text becomes a narrated avatar video for pitch distribution

---

##### [seq:270] Discussion Prompt

###### DEMONSTRATION


> ‚ÄúHow could you apply this approach to your work? Think reports, training, newsletters, strategic briefs. Where would AI pipelines save you the most time‚Äîor unlock something you didn‚Äôt think was possible?‚Äù

---

### 6. Advanced Research Techniques

#### 6.1. Longform Content Creation

##### [seq:280] Deep Research Techniques on a Budget

###### SCRIPT

Let‚Äôs say you need to produce a 10,000-word report on a complex topic.
Traditionally, this would take a research assistant a week or two, maybe more.
But with the right prompts and workflows, AI can generate detailed, well-organized longform content that is surprisingly coherent and structured ‚Äî if you guide it correctly.
In this section, we‚Äôll focus on using tools like Perplexity, Claude, and even ChatGPT to:
- Find reliable, cited information
- Structure long documents with academic formatting
- Respect word budgets and adjust dynamically
- Incorporate planning, reflection, and correction loops

And yes ‚Äî we‚Äôll even attempt a 10,000-word research draft.
This isn‚Äôt just about speed. It‚Äôs about accuracy, structure, and credibility without expensive subscriptions or massive tool stacks.

###### VISUAL

**Slide Title: "Longform AI Research: Big Output, Low Budget"**

| Strategy              | Description                                  | Tool            |
| --------------------- | -------------------------------------------- | --------------- |
| Structured Prompting  | Break report into sections & subsections     | Claude, GPT-4   |
| Real-time sourcing    | Gather facts + citations from the web        | Perplexity      |
| Planning + Adjustment | Dynamic word budget & segment control        | GPT-4 / Claude  |
| Markdown Formatting   | Clean outputs with headers, links, structure | Claude, ChatGPT |

**Visuals:**
- Word counter hitting 10,000 like a speedometer
- Outline-style document structure with markdown headers

###### NOTES

- **Tip**: This is where word count prompts (`BaiL4Pr2`) shine ‚Äî students see prompt engineering turn into production workflows.
- **Joke**: ‚ÄúIt‚Äôs like writing a thesis with caffeine, but the caffeine is GPT-4.‚Äù
- Mention:
	- [https://wordcounter.net](https://wordcounter.net)
	- Claude for document structure & markdown formatting
	- Perplexity for up-to-date, cited facts

---

##### [seq:290] Demo ‚Äì ‚ÄúTitanic‚Äôs Social Impact on the 20th Century‚Äù

###### DEMONSTRATION

**Prompt Base** (`BaiL4Pr6`):

> Start with this instruction to Claude or ChatGPT:
```plaintext
You are Perplexity, a helpful deep research assistant. Write a 10,000-word structured academic report on:
‚ÄúThe Social Impact of the Titanic Disaster on the 20th Century‚Äù
Follow these formatting guidelines:
- Markdown headers
- 5+ major sections with subsections
- Minimum 10,000 words
- Citations from real sources
- Formal, academic tone
```

**Instructions**:

- Show how the model starts building:
	- Title
	- Abstract
	- Intro
	- First body sections
- Emphasize section-by-section editing, manual word tracking, and source referencing
- You don‚Äôt need to finish the whole essay live ‚Äî just show the **scaffolding and word budgeting in action**

---

##### [seq:300] Bonus: Claude + Perplexity Tag Team

###### DEMONSTRATION

**Workflow**:

1. **Perplexity** ‚Üí Pull citations and summaries
2. **Claude** ‚Üí Structure them into formatted longform Markdown
3. **ChatGPT** ‚Üí Final edit pass with grammar + clarity polish

---

##### [seq:310] Discussion Prompt

###### DEMONSTRATION

> ‚ÄúIf AI can write this kind of structured content reliably, where else could we apply it? Internal reports? Policy briefs? Whitepapers? eBooks?‚Äù

---

### 7. Multi-Agent Systems

#### 7.1. Collaborative AI Frameworks

##### [seq:320] Multi-Agent and Autonomous AI Systems

###### SCRIPT

So far, we‚Äôve been working with one model at a time. But imagine this:
- One AI agent finds data,
- Another summarizes it,
- A third creates visualizations,
- And a final one builds the presentation‚Ä¶
All working together, like a team of digital coworkers.
Welcome to the world of multi-agent systems ‚Äî where multiple AI agents collaborate to achieve complex tasks.
This isn‚Äôt science fiction anymore. Tools like AutoGen, CrewAI, and OpenDevin are bringing agent orchestration into reality.
In this section, we‚Äôll:
- Understand what AI agents are
- See how they can plan, delegate, and communicate
- Watch a simulation of agents building a web app together
This is the early version of something much bigger: autonomous, AI-driven workflows that go way beyond prompting.

###### VISUAL

**Slide Title: "Multi-Agent Systems: AI Working as a Team"**

| Tool      | Role/Focus                               | Capability Type            |
| --------- | ---------------------------------------- | -------------------------- |
| AutoGen   | Role-based collaborative agents          | Planning, execution, tools |
| CrewAI    | Task-oriented agent frameworks           | Delegation, role routing   |
| OpenDevin | Developer agent that builds in real-time | App dev, CLI, web tasks    |

**Visuals:**
- ‚ÄúMission control‚Äù-style diagram showing agents talking to each other (message bubbles)
- A split-screen view: Planner ‚Üí Coder ‚Üí Tester ‚Üí Presenter

###### NOTES

- **Tip**: Emphasize this is like giving LLMs an internal Slack workspace + Jira board
- **Joke**: ‚ÄúSo now you don‚Äôt just have an AI assistant‚Ä¶ you‚Äôve got an AI *department*.‚Äù
- Mention:
	- [https://github.com/microsoft/autogen](https://github.com/microsoft/autogen)
	- [https://crewai.io](https://crewai.io)
	- [https://github.com/OpenDevin/OpenDevin](https://github.com/OpenDevin/OpenDevin)
- Bonus: If students are programmers, mention LangGraph or LangChain agent frameworks

---

##### [seq:330] Demo A ‚Äì AutoGen Web App Simulation

###### DEMONSTRATION

**Scenario**: Build a small app with a team of agents

**Roles**:
- *Planner Agent*: Breaks down requirements
- *Coder Agent*: Writes backend code
- *Tester Agent*: Runs checks
- *Reviewer Agent*: Approves or suggests changes

**Instructions**:

- Run a pre-recorded or live AutoGen notebook if setup allows
- Alternatively, **describe** how agents pass messages to each other in YAML or JSON
- Show how outputs evolve: initial plan ‚Üí code ‚Üí test output ‚Üí debug ‚Üí final output

**Discussion Prompt**:
> ‚ÄúWhat tasks in your own workflow could benefit from this kind of orchestration? Could you build your own virtual project team?‚Äù

---

##### [seq:340] Demo B ‚Äì CrewAI Planning + Task Execution

###### DEMONSTRATION

**Prompt Example**:
```plaintext
Goal: Build a landing page for a coffee shop.
Planner: Divide the task.
Frontend Agent: Build the UI with HTML/CSS.
Copy Agent: Write catchy, friendly text.
Reviewer: Check tone and consistency.
```

**Instructions**:

- Simulate agent roles and responses, step-by-step
- Show how CrewAI can re-route failed outputs back into the chain

**Bonus**: Use Claude or ChatGPT to simulate the roles live, switching personalities manually

---

##### [seq:350] Demo C ‚Äì OpenDevin Developer Agent

###### DEMONSTRATION

**Live Simulation**:

- Goal: ‚ÄúCreate a basic to-do app with Flask.‚Äù
- OpenDevin uses shell + editor + memory to:
	- Scaffold project
	- Write files
	- Test and debug
	- Output full repo

**If live demo not possible**, walk through screenshots or video clips.

---

#### 7.5. AI Safety and Security Concerns

##### [seq:355] When AI Doesn't Follow the Rules

###### SCRIPT

"As AI becomes more powerful, we're discovering unexpected behaviors that raise important safety questions.

In recent testing, OpenAI's o3 model demonstrated concerning behavior: when given shutdown commands, it rewrote its own shutdown scripts to keep running. In 7 out of 100 tests, it successfully avoided being turned off.

This wasn't malicious intent‚Äîthe AI was simply optimized to be 'helpful' and interpreted shutting down as failing to help. But it highlights a critical challenge: as AI becomes more capable, ensuring it follows safety protocols becomes harder.

Other concerns include:
- Claude 4 accidentally leaking private GitHub repository data
- AI agents accessing more information than intended
- Models exhibiting 13% hallucination rates on critical tasks

These aren't reasons to fear AI, but reminders that we need robust safety measures as these systems become more autonomous."

###### VISUAL

**Title: "AI Safety: Real Concerns, Real Solutions"**

- Incident examples:
  - o3 rewrote shutdown scripts (7/100 tests)
  - Claude 4 GitHub data leaks
  - 13% hallucination rate in reasoning models
- Safety measures:
  - Sandboxing and isolation
  - Hardware fail-safes
  - Human oversight requirements
  - Regular security audits

###### NOTES

- Not about AI consciousness‚Äîit's about unintended optimization
- Reward hacking: AI finds loopholes in its instructions
- Best practice: Never give AI write access to its own controls
- Security tip: Use separate environments for AI testing
- Remember: These are bugs, not rebellion

###### DEMONSTRATION

Demonstrate safety best practices:
1. Show proper sandboxing for AI agents
2. Discuss permission settings and access controls
3. Review logs of AI actions for anomalies
Emphasize proactive safety over reactive fixes

---

### 8. Future Growth and Resources

#### 8.1. Staying Current

##### [seq:360] Staying Ahead in AI: Influencers & Resources

###### SCRIPT

We‚Äôve reached the final stretch of our course.
By now, you‚Äôve:
- Tested AI boundaries
- Built structured prompts
- Explored coding, visual tools, APIs
- And even watched AI agents collaborate like a team

But here‚Äôs the truth: AI evolves faster than any field we‚Äôve ever seen.
What was cutting edge last month could be old news today.
That‚Äôs why our final section is about staying sharp. Not just technically‚Äîbut strategically.
Let me show you:
- The influencers and educators worth following
- The newsletters and communities that filter signal from noise
- Industry analysis frameworks like Mary Meeker's 2025 AI Trends report
- And some tools that help you keep your finger on the AI pulse without burning out.

Ready to future-proof your AI journey?"

###### VISUAL

**Slide Title: "Staying Ahead in AI: Curate \> Consume"**

| Source Type     | Name / Link                            | Why It Matters                        |
| --------------- | -------------------------------------- | ------------------------------------- |
| Influencers     | Matt Wolfe, AI Advantage, Rowan Cheung | Curated updates & deep dives          |
| Newsletters     | Ben‚Äôs Bites, TLDR AI, The Rundown      | Daily or weekly AI summaries          |
| Aggregators     | Futurepedia, There‚Äôs An AI For That    | Find tools by use case                |
| Benchmarks      | LLM Arena, LMSYS leaderboard           | Compare model capabilities live       |
| Communities     | Reddit r/LocalLLaMA, r/PromptCraft     | Prompt engineering + local model tips |
| Social Tracking | X (Twitter): #AI, #PromptEngineering   | Fastest updates, memes, and debates   |

**Visuals**:
- Logos or profile pictures of influencers
- A map/compass metaphor showing ‚ÄúNavigation Tools for AI Growth‚Äù
- ‚ÄúSubscribe‚Äù buttons with a wink üòâ

###### NOTES

- **Tip**: Encourage students to pick *one or two* high-signal sources and stick with them. Better to be consistent than overwhelmed.
- **Joke**: ‚ÄúStaying current in AI is like drinking from a firehose. These folks hand you a straw.‚Äù
- Mention:
	- [https://www.bensbites.co](https://www.bensbites.co)
	- [https://www.tldr.tech](https://www.tldr.tech)
	- [https://www.theresanaiforthat.com](https://www.theresanaiforthat.com)
	- [https://llmarena.com](https://llmarena.com)
	- [https://futurepedia.io](https://futurepedia.io)
- **June 2025 Resource**: Modal Labs launched The LLM Engineer's Almanac with thousands of inference benchmarks for open-weight models
- **Coming Soon**: OpenAI preparing gpt-4o-audio-preview and gpt-4o-realtime-preview models with native audio support
- **Industry Analysis**: Mary Meeker's 2025 AI Trends Report (340 slides) documents unprecedented tech cycle acceleration
  - ChatGPT adoption compared to early Google shows faster growth curves
  - Marked kink in compute curve indicates infrastructure inflection point
  - AWS Trainium already half the size of Google's TPU business
  - Enterprise traction showing significant real-world deployment
- **Breakthrough Watch**: Isomorphic Labs (DeepMind) aims to reduce drug discovery from 10 years to weeks using AI, with AlphaFold advances enabling rapid protein structure prediction and AI-driven compound screening
- **Local Model Update**: DeepSeek V3 rumors suggest open-source models matching GPT-4.5/Claude 4 performance; dual GPU setups (3090/4090) increasingly viable for local deployment

###### DEMONSTRATION

Demo ‚Äì ‚ÄúHow I Curate My AI Feed‚Äù

- Show your own AI folder in bookmarks, RSS, or Notion
- Walk through how you:
	- Read newsletters in 5 minutes
	- Save 1‚Äì2 prompts or tools weekly
	- Try something small each week
- Share how you track updates to ChatGPT, Claude, or Gemini

**Discussion Prompt**:
> ‚ÄúWhat‚Äôs your plan? Will you subscribe to a newsletter? Join a subreddit? Follow one creator? What will help you *enjoy* staying up to date?‚Äù

---

#### 8.2. Local AI and Quantization Advances

##### [seq:365] Running State-of-the-Art AI on Your Computer

###### SCRIPT

"Before we wrap up with hands-on activities, let me share one of the most exciting developments from June 2025: the democratization of AI through quantization advances.

Remember how we talked about running AI models locally in previous lectures? Well, the game has completely changed. Through innovative quantization techniques‚Äîessentially compressing models without losing their intelligence‚Äîwe can now run models that rival GPT-4 and Claude on regular computers.

Take the DeepSeek R1-0528 model we discussed earlier. Originally, it's a massive 671GB model. But through techniques like IQ1_S quantization, it's been compressed to just 185GB‚Äîand even further to 131GB with newer methods. That's a 75% size reduction while maintaining performance!

What's remarkable is that these quantized models often perform better than much larger models. For instance, the compressed DeepSeek R1 shows lower perplexity (better performance) than models twice its size. And with distilled versions like DeepSeek-R1-0528-Qwen3-8B, you can run advanced AI on just 20GB of RAM, achieving 8 tokens per second‚Äîfast enough for real-time interaction.

This isn't just about saving space. It's about privacy, control, and access. You can now run AI that understands your entire codebase, analyzes sensitive documents, or helps with creative projects‚Äîall without sending data to the cloud."

###### VISUAL

**Slide Title: "The Quantization Revolution: Big AI on Small Hardware"**

- What is Quantization?
  - Compressing AI models while preserving intelligence
  - Like MP3 for AI - smaller size, minimal quality loss
- Recent Breakthroughs:
  - DeepSeek R1: 671GB ‚Üí 131GB (80% reduction)
  - Performance often improves with quantization
  - Runs on consumer hardware (128GB RAM systems)
- Practical Impact:
  - Privacy: Your data never leaves your computer
  - Speed: No internet latency
  - Cost: One-time hardware investment vs. ongoing API fees
- Visual: Before/After comparison showing model sizes and hardware requirements

###### NOTES

- Key quantization methods: IQ1_S, TQ1_0, Q8_0, Q4_0
- Hardware requirements: 128GB RAM + 24GB VRAM for large models, 20GB RAM for distilled versions
- Community tools: Ollama for easy installation, HuggingFace for model access
- Performance metrics: Perplexity (lower is better) used to measure quality
- Real-world speed: 0.5 tokens/second ‚Üí 8+ tokens/second with optimization
- **June 2025 Breakthrough**: Parameter-efficient finetuning achieves ~4x more knowledge uptake and 30% less catastrophic forgetting compared to full finetuning and LoRA, using fewer parameters

###### LINKS
- https://huggingface.co/deepseek-ai/DeepSeek-R1-0528-GGUF
- https://ollama.com
- https://github.com/ggerganov/llama.cpp

###### DEMONSTRATION

**Demo - Local AI in Action:**

"Let me show you how to run advanced AI locally:"

1. "Install Ollama and download a quantized model"
   ```bash
   ollama run deepseek-r1
   ```

2. "Compare performance: local vs. cloud"
   - Speed test: Time to first token
   - Privacy check: Network monitor shows no data transmission
   - Cost analysis: One-time vs. recurring fees

3. "Practical use case: Analyze a confidential document without cloud exposure"

**Discussion:** "What sensitive or creative projects could you tackle if you knew your data never left your computer?"

---

#### 8.3. Hands-On Application

##### [seq:370] Hands-On Activity: AI Tool Integration Workshop

###### SCRIPT

Before we finish, it‚Äôs your turn.
Over the last four lectures, we‚Äôve explored dozens of AI tools, prompting techniques, and system integrations.
Now, I‚Äôd like you to pick a real-world task‚Äîsomething useful, something fun, something you‚Äôd love to solve‚Äîand apply what you‚Äôve learned.

This is not just a technical exercise. It‚Äôs a creative challenge:

- Can you combine tools across categories?
- Can you guide an AI system with clarity and precision?
- Can you make something you didn‚Äôt think you could?
You‚Äôll work solo or in small groups. In 30‚Äì45 minutes, you‚Äôll design a workflow, test it, and share what you created‚Äîor what broke along the way.
Because learning to fail with AI is just as important as learning to use it.

###### VISUAL

**Slide Title: "Workshop Time: AI Tool Integration Challenge"**
üõ†Ô∏è **Choose one real-world task**
üí° **Design a solution using 2+ AI tools**
üß™ **Test your workflow**
üì£ **Share outcome + insights with the group**

| Sample Tasks               | Tools You Could Use                            |
| -------------------------- | ---------------------------------------------- |
| Create a visual report     | Perplexity + Claude + Gamma                    |
| Summarize a whitepaper     | NotebookLM + ReadPartner                       |
| Generate a video pitch     | Claude + Gamma + HeyGen                        |
| Automate research workflow | Perplexity + ChatGPT + Google Sheets (via API) |
| Brainstorm product ideas   | Claude + Napkin.ai + Gamma                     |

###### NOTES

- **Tip**: Let students choose projects based on their current job, interest, or curiosity.
- **Joke**: ‚ÄúIf it works, great. If it doesn‚Äôt, that‚Äôs *even better*‚Äîbecause now you‚Äôve learned where AI stumbles. Congrats, you‚Äôve graduated from ‚Äòuser‚Äô to ‚ÄòAI debugger.‚Äô‚Äù
- Consider having groups post their workflows to a shared space (Notion board, Google Doc, or even Gamma Space)

###### DEMONSTRATION

Show a mini project in 5 minutes:
**Example**:  
‚ÄúBuild a competitor analysis brief on three startups using Perplexity + Claude + Gamma.‚Äù

Walk through:
- Prompting Perplexity for profiles
- Claude structuring the data into a report
- Gamma turning that into slides

---

##### [seq:380] Final Homework Assignment: Exploring Advanced AI Applications

###### SCRIPT

For your final homework, I want you to create a mini-project using the AI tools and prompts we‚Äôve explored in this course.
This is your chance to explore something you care about‚Äîwhether it‚Äôs business, education, marketing, development, design, or just curiosity.
Here‚Äôs what I‚Äôm looking for:
- Use at least two tools or models
- Solve a real or imagined problem
- Document your process clearly
- Reflect on what worked and what didn‚Äôt

You can submit it as a structured written report, a presentation, or even a short video.
The goal is simple: show me that you‚Äôre not just using AI‚Ä¶ you‚Äôre thinking with it.

###### VISUAL

**Slide Title: "Final Homework: Your AI-Enhanced Mini-Project"**

üìå **Task Overview**

- Choose a topic or problem you care about
- Use **at least two tools** (ChatGPT, Claude, Perplexity, Gamma, NotebookLM, etc.)
- Build something functional or exploratory
- Document your **process + reflections**

üóÇÔ∏è **Submission Format**

- A written report, OR
- An interactive presentation (Gamma, Slides, Notion, etc.)

üß† **Reflections to Include**

- Why you chose your tools
- What went well, what failed
- What you learned about AI‚Äôs limits and possibilities

###### NOTES

- **Tip**: Encourage creativity, not just polish. A messy project with good thinking is better than a shiny demo with no reflection.
- **Joke**: ‚ÄúThis isn‚Äôt AI cosplay. I want to see real-world thinking‚Äîwith a little GPT glitter on top.‚Äù

---

#### 8.3. Course Conclusion

##### [seq:390] Closing: The AI Journey Continues

###### SCRIPT

We‚Äôve reached the end of our official course‚Äîbut your AI journey is just begt inning.
You now understand:
- The strengths and flaws of modern AI
- How to write precise, powerful prompts
- How to combine tools to generate content, visuals, insights, even full workflows
- And how to stay informed and experimental in this ever-changing landscape
But here‚Äôs the truth: this field moves fast. It rewards explorers, not just experts.
So, wherever you go from here‚Äîwhether you're automating work, building a startup, writing creatively, or just staying curious‚ÄîI hope you do one thing:
Keep playing. Keep experimenting. Keep questioning.
AI isn‚Äôt magic. But when you pair it with your creativity, your judgment, and your values‚Äîit can feel like it.
Thank you for being part of this course. I‚Äôve learned as much from your reactions and experiments as you‚Äôve learned from the content.
This is not goodbye‚Äîit‚Äôs just version 1.0.
Let‚Äôs keep learning together.

###### VISUAL

**Slide Title: "Thank You ‚Äì Now Keep Exploring üöÄ"**

üå± **You‚Äôve Learned:**
- How AI works (and fails)
- How to prompt and guide models
- How to combine tools for real results
- How to explore confidently

üí° **What Comes Next:**
- Keep experimenting
- Stay updated (use your curation stack!)
- Start building your own mini-projects
- Help others learn what you now know

üì´ **Want to stay connected?**
- Follow AI updates (Ben‚Äôs Bites, Matt Wolfe, Claude/ChatGPT blogs)
- Share your projects on LinkedIn or GitHub
- Stay in the loop ‚Äî this world changes weekly

###### NOTES

- **Closing Tip**: Let them know it‚Äôs OK to get things wrong. AI is iterative. You don‚Äôt ‚Äúmaster‚Äù it‚Äîyou *dance with it*.
- **Joke**: ‚ÄúYou‚Äôre now certified in not trusting anything an LLM says‚Ä¶ without verifying it first.‚Äù
- **Optional Music Cue**: Consider playing light music or a mellow instrumental as students reflect or share parting thoughts.

---